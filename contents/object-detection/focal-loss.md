---
id: focal-loss
title: 'Focal Loss for Dense Object Detection'
sidebar_label: Focal Loss
keywords:
  [
    focal loss,
    focal loss for dense object detection,
    dense object detection,
    dense object detection with focal loss,
  ]
---

> Citations: 1,206  | Paper Published: 07 Aug 2017 | Institutions: Facebook | Authors: Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, Piotr Doll√°r

<!-- Prettier doesn't change this -->
:::tip Abstract in 2 Lines

The paper proposes a new loss function called Focal Loss to address the class imbalance problem in dense object detectors. They use this loss function to train a new one-stage detector called RetinaNet, which achieves state-of-the-art accuracy while maintaining fast speed.

:::


## Contributions 

- Proposing a new loss function called Focal Loss to address the class imbalance problem in dense object detectors.
- Introducing a new one-stage detector called RetinaNet, which achieves state-of-the-art accuracy while maintaining fast speed by using the proposed Focal Loss.
- Showing that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause of the lower accuracy of one-stage detectors compared to two-stage detectors.

## Practical Implications

- The proposed Focal Loss can be used to improve the accuracy of dense object detectors, which can be useful in various computer vision applications such as autonomous driving, robotics, and surveillance.
- The new one-stage detector called RetinaNet can be used as a fast and accurate object detector in real-world scenarios where speed and accuracy are both important.
- The insights gained from this paper about the class imbalance problem in dense object detectors can be useful for researchers and practitioners working on similar problems in computer vision.


## Methods
<!-- Prettier doesn't change this -->
:::info Methodology

- The paper proposes a new loss function called Focal Loss to address the class imbalance problem in dense object detectors. The Focal Loss down-weights the loss assigned to well-classified examples and focuses training on a sparse set of hard examples.
- The paper introduces a new one-stage detector called RetinaNet, which uses the proposed Focal Loss to achieve state-of-the-art accuracy while maintaining fast speed.
- The paper evaluates the effectiveness of the proposed Focal Loss and RetinaNet on various object detection benchmarks such as COCO and PASCAL VOC.

:::

## Data
The paper uses the COCO dataset, which is a large-scale object detection, segmentation, and captioning dataset. The dataset contains over 330K images with more than 2.5 million object instances labeled with 80 different object categories.

## Results
<!-- Prettier doesn't change this -->
:::note Performance Analysis

- RetinaNet achieves a mean average precision (mAP) of 39.1% on the COCO test-dev dataset, which is the highest reported accuracy among all existing one-stage detectors and surpasses the accuracy of all existing state-of-the-art two-stage detectors.
- RetinaNet achieves this high accuracy while maintaining a fast speed of 5 frames per second on a GPU.
- The proposed Focal Loss significantly improves the accuracy of RetinaNet, especially for small and medium-sized objects. For example, the mAP for small objects (area < 32^2 pixels) improves from 11.8% to 28.1% with the Focal Loss.

:::


## Limitations

The limitations of this paper are not explicitly mentioned. However, one potential limitation could be that the proposed Focal Loss may not work as well on datasets other than COCO and PASCAL VOC. Further evaluation on other datasets is needed to confirm the generalizability of the proposed method.


